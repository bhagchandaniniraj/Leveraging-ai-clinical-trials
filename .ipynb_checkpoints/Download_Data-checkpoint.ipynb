{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0fa8b7-8ce9-4cc9-bb07-263b9cdf205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from json import JSONDecodeError\n",
    "import sqlite3\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from queue import Queue\n",
    "from threading import Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab129e4-0a57-429b-a7df-7170857f5255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting download of all clinical trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pages : 1993 page [1:09:38,  2.60s/ page]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Error fetching page: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pages : 5350 page [2:58:57,  1.79s/ page]"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "PAGE_SIZE = 100  # API max is 100\n",
    "OUTPUT_FILE = \"clinical_trials_full.json\"\n",
    "SLEEP_BETWEEN_REQUESTS = 0.5  # seconds\n",
    "\n",
    "def fetch_all_studies():\n",
    "    \"\"\"Fetch all studies from ClinicalTrials.gov API v2 and write to a JSON file.\"\"\"\n",
    "    print(\"üöÄ Starting download of all clinical trials...\")\n",
    "    next_token = None\n",
    "    total_fetched = 0\n",
    "    first_record = True\n",
    "\n",
    "    # Open output file and write opening bracket for JSON array\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(\"[\\n\")\n",
    "\n",
    "        with tqdm(desc=\"Downloading pages \", unit=\" page\") as pbar:\n",
    "            while True:\n",
    "                params = {\"pageSize\": PAGE_SIZE}\n",
    "                if next_token:\n",
    "                    params[\"pageToken\"] = next_token\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(BASE_URL, params=params, timeout=30)\n",
    "                    response.raise_for_status()\n",
    "                    data = response.json()\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error fetching page: {e}\")\n",
    "                    print(\"Retrying in 5 seconds...\")\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "\n",
    "                studies = data.get(\"studies\", [])\n",
    "                if not studies:\n",
    "                    break\n",
    "\n",
    "                for study in studies:\n",
    "                    # Write comma before every record except the first\n",
    "                    if not first_record:\n",
    "                        outfile.write(\",\\n\")\n",
    "                    json.dump(study, outfile, ensure_ascii=False)\n",
    "                    first_record = False\n",
    "                    total_fetched += 1\n",
    "\n",
    "                next_token = data.get(\"nextPageToken\")\n",
    "                pbar.update(1)\n",
    "\n",
    "                if not next_token:\n",
    "                    break\n",
    "\n",
    "                time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "        # Close JSON array\n",
    "        outfile.write(\"\\n]\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Download complete. Total studies saved: {total_fetched}\")\n",
    "    print(f\"Output file: {OUTPUT_FILE}\")\n",
    "\n",
    "    # Show the first two records for verification\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            all_data = json.load(f)\n",
    "            print(f\"\\nFirst two records:\")\n",
    "            print(json.dumps(all_data[:2], indent=2))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load output file for verification: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_all_studies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25779a51-0bc8-46e6-a5c2-49a4de0a3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File can be opened for reading.\n",
      "‚ùå Could not open or parse clinical_trials_full.json: \n",
      "\n",
      "‚úÖ Finished streaming validation.\n",
      "Total records parsed: 541402\n",
      "Total errors encountered: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "filepath = \"clinical_trials_full.json\"\n",
    "\n",
    "# Step 1: File existence\n",
    "if not os.path.isfile(filepath):\n",
    "    print(f\"‚ùå File not found: {filepath}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: File permissions\n",
    "try:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        f.read(1)\n",
    "    print(\"‚úÖ File can be opened for reading.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå File cannot be opened: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Step 3: Try JSON validation\n",
    "try:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        json.load(f)\n",
    "    print(f\"‚úÖ {filepath} is valid JSON.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"‚ùå JSON syntax error in {filepath}:\")\n",
    "    print(f\"   Line {e.lineno}, Column {e.colno}: {e.msg}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not open or parse {filepath}: {e}\")\n",
    "\n",
    "import ijson\n",
    "\n",
    "filepath = \"clinical_trials_full.json\"\n",
    "record_count = 0\n",
    "error_count = 0\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    try:\n",
    "        for record in ijson.items(f, 'item'):\n",
    "            record_count += 1\n",
    "            # Optionally, add further validation here\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while parsing record {record_count+1}: {e}\")\n",
    "        error_count += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Finished streaming validation.\")\n",
    "print(f\"Total records parsed: {record_count}\")\n",
    "print(f\"Total errors encountered: {error_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463707bd-32b1-43f3-8e10-08072e63f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def count_records_with_progress(input_file):\n",
    "    file_size = os.path.getsize(input_file)\n",
    "    count = 0\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        for _ in tqdm(data, desc='Counting records'):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "input_filename = 'clinical_trials_full.json'\n",
    "record_count = count_records_with_progress(input_filename)\n",
    "print(f\"\\nTotal records in {input_filename}: {record_count}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
