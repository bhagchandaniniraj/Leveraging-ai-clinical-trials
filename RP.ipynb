{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install stable-baselines3 torch transformers xgboost scikit-learn pandas requests tenacity gymnasium tqdm imbalanced-learn psutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from stable_baselines3 import PPO\n",
    "import pandas as pd\n",
    "import requests\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import os\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import psutil\n",
    "import sys\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# File to save the API data\n",
    "DATA_FILE = \"clinical_trials_data.csv\"\n",
    "# Lock for thread-safe CSV writing\n",
    "csv_lock = threading.Lock()\n",
    "# Temporary file for intermediate results\n",
    "TEMP_FILE = \"temp_data.npz\"\n",
    "\n",
    "# Function to check available RAM\n",
    "def check_available_ram():\n",
    "    memory = psutil.virtual_memory()\n",
    "    available_ram = memory.available / (1024 ** 3)  # Convert to GB\n",
    "    logging.info(f\"Available RAM: {available_ram:.2f} GB\")\n",
    "    return available_ram\n",
    "\n",
    "# Step 1: Fetch Total Number of Studies with Parallel Estimation and Progress Bar\n",
    "def fetch_page_for_count(page_token=None):\n",
    "    base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "    params = {\n",
    "        \"pageSize\": 100,\n",
    "        \"pageToken\": page_token\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            studies = data.get('studies', [])\n",
    "            next_page_token = data.get('nextPageToken')\n",
    "            return len(studies), next_page_token\n",
    "        else:\n",
    "            logging.error(f\"Error fetching page for count: {response.status_code} - {response.text}\")\n",
    "            return 0, None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception during page fetch for count: {e}\")\n",
    "        return 0, None\n",
    "\n",
    "def get_total_study_count(max_workers=1):  # Further reduced workers to manage RAM\n",
    "    try:\n",
    "        # First, try the /stats/size endpoint\n",
    "        base_url = \"https://clinicaltrials.gov/api/v2/stats/size\"\n",
    "        response = requests.get(base_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            total_studies = data.get('studies', 0)\n",
    "            if total_studies > 0:\n",
    "                logging.info(f\"Total studies from /stats/size: {total_studies}\")\n",
    "                return total_studies\n",
    "\n",
    "        # If /stats/size fails or returns 0, estimate by fetching pages in parallel with a progress bar\n",
    "        logging.warning(\"Failed to get total study count from /stats/size. Estimating via parallel fetch...\")\n",
    "        total_count = 0\n",
    "        next_page_token = None\n",
    "        page_tokens = [None]  # Start with the first page\n",
    "        max_pages_to_estimate = 10  # Limit estimation to 10 pages to avoid infinite loop\n",
    "\n",
    "        with tqdm(total=max_pages_to_estimate * 100, desc=\"Estimating total studies\", unit=\"studies\") as pbar:\n",
    "            pages_fetched = 0\n",
    "            while page_tokens and pages_fetched < max_pages_to_estimate:\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                    future_to_token = {executor.submit(fetch_page_for_count, token): token for token in page_tokens}\n",
    "                    page_tokens = []\n",
    "\n",
    "                    for future in concurrent.futures.as_completed(future_to_token):\n",
    "                        page_count, next_token = future.result()\n",
    "                        total_count += page_count\n",
    "                        pbar.update(page_count)\n",
    "                        if next_token:\n",
    "                            page_tokens.append(next_token)\n",
    "                pages_fetched += 1\n",
    "\n",
    "        # Estimate total based on pages fetched\n",
    "        if total_count > 0:\n",
    "            pages_fetched = total_count // 100\n",
    "            estimated_total = total_count * (max_pages_to_estimate / pages_fetched) if pages_fetched > 0 else total_count * 10\n",
    "            logging.info(f\"Estimated total studies: {int(estimated_total)}\")\n",
    "            return int(estimated_total)\n",
    "        else:\n",
    "            logging.warning(\"Could not estimate total study count. Using default large number for progress.\")\n",
    "            return 100000  # Default large number for progress bar\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred while fetching total study count: {e}\")\n",
    "        return 100000  # Default large number for progress bar\n",
    "\n",
    "# Step 1.1: Count Records in CSV with Progress Bar (Memory-Efficient)\n",
    "def check_existing_csv():\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        return 0  # File doesn't exist, need to download\n",
    "\n",
    "    try:\n",
    "        total_records = 0\n",
    "        file_size = os.path.getsize(DATA_FILE) // (1024 ** 2)  # File size in MB\n",
    "        with open(DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            with tqdm(total=file_size, desc=\"Counting CSV records\", unit=\"MB\") as pbar:\n",
    "                for _ in reader:\n",
    "                    total_records += 1\n",
    "                    # Update progress bar based on current position in file\n",
    "                    current_pos = f.tell() // (1024 ** 2)  # Current position in MB\n",
    "                    pbar.n = min(current_pos, file_size)  # Update progress\n",
    "                    pbar.refresh()\n",
    "        # Subtract 1 for the header row\n",
    "        total_records -= 1\n",
    "        logging.info(f\"Existing CSV contains {total_records} records.\")\n",
    "        return total_records\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading existing CSV: {e}. Will re-download data.\")\n",
    "        return 0\n",
    "\n",
    "# Step 1.2: Fetch a Single Page of Data\n",
    "def fetch_page(page_token=None):\n",
    "    base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "    params = {\n",
    "        \"pageSize\": 100,\n",
    "        \"pageToken\": page_token\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"Error fetching page with token {page_token}: {response.status_code} - {response.text}\")\n",
    "            return None, None\n",
    "        data = response.json()\n",
    "        studies = data.get('studies', [])\n",
    "        next_page_token = data.get('nextPageToken')\n",
    "        return studies, next_page_token\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred during API request for page with token {page_token}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Step 1.3: Save Fetched Studies to CSV (Thread-Safe)\n",
    "def save_to_csv(studies):\n",
    "    if not studies:\n",
    "        return\n",
    "\n",
    "    df_page = pd.json_normalize(studies)\n",
    "    with csv_lock:\n",
    "        mode = 'a' if os.path.exists(DATA_FILE) else 'w'\n",
    "        header = not os.path.exists(DATA_FILE)\n",
    "        df_page.to_csv(DATA_FILE, mode=mode, header=header, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Step 1.4: Fetch All Data from ClinicalTrials.gov API with Parallel Downloads\n",
    "def fetch_clinical_trials(max_workers=1):  # Further reduced workers to manage RAM\n",
    "    check_available_ram()\n",
    "    total_studies = get_total_study_count(max_workers=max_workers)\n",
    "    if total_studies == 0:\n",
    "        logging.warning(\"API returned 0 studies. Attempting to fetch at least one page...\")\n",
    "        studies, next_page_token = fetch_page()\n",
    "        if studies:\n",
    "            total_studies = max(len(studies) * 100, 100000)  # Rough estimate\n",
    "        else:\n",
    "            logging.error(\"No studies fetched. Using default large number for progress.\")\n",
    "            total_studies = 100000\n",
    "\n",
    "    existing_records = check_existing_csv()\n",
    "    if existing_records >= total_studies > 0:\n",
    "        logging.info(\"CSV file already contains all records. Skipping download.\")\n",
    "    else:\n",
    "        if os.path.exists(DATA_FILE):\n",
    "            os.remove(DATA_FILE)\n",
    "\n",
    "        studies_fetched = 0\n",
    "        next_page_token = None\n",
    "        page_tokens = [None]\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            with tqdm(total=total_studies, desc=\"Fetching studies\", unit=\"studies\") as pbar:\n",
    "                while page_tokens:\n",
    "                    check_available_ram()\n",
    "                    if psutil.virtual_memory().available / (1024 ** 3) < 0.5:  # Less than 0.5 GB available\n",
    "                        logging.warning(\"Low RAM available. Pausing fetch to free memory...\")\n",
    "                        sys.stdout.flush()\n",
    "                        break\n",
    "                    future_to_token = {executor.submit(fetch_page, token): token for token in page_tokens}\n",
    "                    page_tokens = []\n",
    "\n",
    "                    for future in concurrent.futures.as_completed(future_to_token):\n",
    "                        studies, next_token = future.result()\n",
    "                        if studies:\n",
    "                            save_to_csv(studies)\n",
    "                            studies_fetched += len(studies)\n",
    "                            pbar.update(len(studies))\n",
    "                        if next_token:\n",
    "                            page_tokens.append(next_token)\n",
    "\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        logging.error(\"No data was fetched. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    logging.info(f\"\\nReading fetched data from {DATA_FILE}...\")\n",
    "    df_chunks = pd.read_csv(DATA_FILE, chunksize=250, quoting=csv.QUOTE_ALL, on_bad_lines='skip')  # Further reduced chunk size\n",
    "    df = pd.concat(df_chunks, ignore_index=True)\n",
    "    logging.info(f\"Fetched {len(df)} studies from ClinicalTrials.gov.\")\n",
    "    return df\n",
    "\n",
    "# Step 1.5: Analyze the Fetched Data\n",
    "def analyze_data(df):\n",
    "    if df.empty:\n",
    "        logging.info(\"No data to analyze.\")\n",
    "        return\n",
    "\n",
    "    logging.info(\"\\nDataset Analysis:\")\n",
    "    logging.info(f\"Total number of studies: {len(df)}\")\n",
    "\n",
    "    studies_with_results = df[df['resultsSection'].notna()]\n",
    "    logging.info(f\"Number of studies with results: {len(studies_with_results)}\")\n",
    "\n",
    "    if 'protocolSection.designModule.studyType' in df:\n",
    "        study_types = df['protocolSection.designModule.studyType'].value_counts()\n",
    "        logging.info(\"\\nStudy Types Distribution:\")\n",
    "        logging.info(study_types.to_string())\n",
    "\n",
    "    if 'protocolSection.designModule.phases' in df:\n",
    "        phases = df['protocolSection.designModule.phases'].explode().value_counts()\n",
    "        logging.info(\"\\nPhases Distribution:\")\n",
    "        logging.info(phases.to_string())\n",
    "\n",
    "    if 'resultsSection.resultsFirstPostDate' in df:\n",
    "        results_dates = pd.to_datetime(df['resultsSection.resultsFirstPostDate'].dropna())\n",
    "        if not results_dates.empty:\n",
    "            logging.info(\"\\nResults First Posted Date Range:\")\n",
    "            logging.info(f\"Earliest: {results_dates.min()}\")\n",
    "            logging.info(f\"Latest: {results_dates.max()}\")\n",
    "\n",
    "    if 'protocolSection.armsInterventionsModule.interventions' in df:\n",
    "        interventions_present = df['protocolSection.armsInterventionsModule.interventions'].notna().sum()\n",
    "        logging.info(f\"\\nNumber of studies with interventions: {interventions_present}\")\n",
    "\n",
    "    if 'resultsSection.outcomeMeasuresModule.outcomeMeasures' in df:\n",
    "        outcomes_present = df['resultsSection.outcomeMeasuresModule.outcomeMeasures'].notna().sum()\n",
    "        logging.info(f\"Number of studies with outcome measures: {outcomes_present}\")\n",
    "\n",
    "# Step 1.6: Fallback Simulated Data if API Returns Insufficient Results\n",
    "def simulate_clinical_data(n_samples=1000):\n",
    "    logging.info(\"Simulating clinical trial data as fallback...\")\n",
    "    X_num = np.random.rand(n_samples, 3)  # age, sex, dosage\n",
    "    X_text = [\"Simulated summary\"] * n_samples\n",
    "    y = np.random.randint(0, 2, size=n_samples)  # ADE occurrence (0 or 1)\n",
    "    return X_num, X_text, y\n",
    "\n",
    "# Step 2: Preprocess API Data and Simulate Patient-Level Data (A) with Temporary File Saving\n",
    "def preprocess_clinical_data(df, min_samples=1000, chunk_size=100):\n",
    "    if df.empty or len(df) < 5:\n",
    "        logging.info(\"Insufficient data from API. Using simulated data.\")\n",
    "        return simulate_clinical_data(n_samples=min_samples)\n",
    "\n",
    "    # Initialize lists for chunked processing\n",
    "    numerical_features_chunks = []\n",
    "    textual_data_chunks = []\n",
    "    labels_chunks = []\n",
    "\n",
    "    chunk_numerical = []\n",
    "    chunk_textual = []\n",
    "    chunk_labels = []\n",
    "    chunk_count = 0\n",
    "\n",
    "    with tqdm(total=len(df), desc=\"Preprocessing data\", unit=\"rows\") as pbar:\n",
    "        for idx, row in df.iterrows():\n",
    "            enrollment = row.get('protocolSection.eligibilityModule.enrollmentCount', 0)\n",
    "            if enrollment == 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            age_group = row.get('protocolSection.eligibilityModule.minimumAge', 'ADULT, OLDER_ADULT')\n",
    "            sex = row.get('protocolSection.eligibilityModule.sex', 'ALL')\n",
    "            interventions = row.get('protocolSection.armsInterventionsModule.interventions', [{}])\n",
    "            outcomes = row.get('resultsSection.outcomeMeasuresModule.outcomeMeasures', [{}])\n",
    "            summary = row.get('protocolSection.descriptionModule.briefSummary', \"No summary available\")\n",
    "\n",
    "            ade_prob = 0.3\n",
    "            for outcome in outcomes:\n",
    "                title = outcome.get('title', '').lower()\n",
    "                description = outcome.get('description', '').lower()\n",
    "                if 'adverse event' in title or 'safety' in title or 'adverse event' in description or 'safety' in description:\n",
    "                    ade_prob = 0.5\n",
    "                    break\n",
    "\n",
    "            dosage = 1.0\n",
    "            for intervention in interventions:\n",
    "                name = intervention.get('name', '').lower()\n",
    "                if '60mg/m2' in name:\n",
    "                    dosage = 60.0\n",
    "                elif '80mg/m2' in name:\n",
    "                    dosage = 80.0\n",
    "                elif '100mg/m2' in name:\n",
    "                    dosage = 100.0\n",
    "\n",
    "            for _ in range(int(enrollment)):\n",
    "                if 'ADULT' in age_group and 'OLDER_ADULT' in age_group:\n",
    "                    age = np.random.randint(18, 100)\n",
    "                elif 'ADULT' in age_group:\n",
    "                    age = np.random.randint(18, 65)\n",
    "                else:\n",
    "                    age = np.random.randint(65, 100)\n",
    "\n",
    "                sex_val = np.random.choice([0, 1])\n",
    "                chunk_numerical.append([age, sex_val, dosage])\n",
    "                chunk_textual.append(summary)\n",
    "                label = 1 if np.random.random() < ade_prob else 0\n",
    "                chunk_labels.append(label)\n",
    "\n",
    "                chunk_count += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "                # Save chunk to temporary file when it reaches chunk_size\n",
    "                if chunk_count >= chunk_size:\n",
    "                    numerical_features_chunks.append(np.array(chunk_numerical))\n",
    "                    textual_data_chunks.append(chunk_textual)\n",
    "                    labels_chunks.append(np.array(chunk_labels))\n",
    "                    # Save to temporary file\n",
    "                    with open(TEMP_FILE, 'ab') as f:\n",
    "                        np.savez(f, numerical=np.array(chunk_numerical), textual=np.array(chunk_textual, dtype=object), labels=np.array(chunk_labels))\n",
    "                    chunk_numerical = []\n",
    "                    chunk_textual = []\n",
    "                    chunk_labels = []\n",
    "                    chunk_count = 0\n",
    "                    check_available_ram()\n",
    "\n",
    "    # Save any remaining data\n",
    "    if chunk_numerical:\n",
    "        numerical_features_chunks.append(np.array(chunk_numerical))\n",
    "        textual_data_chunks.append(chunk_textual)\n",
    "        labels_chunks.append(np.array(chunk_labels))\n",
    "        with open(TEMP_FILE, 'ab') as f:\n",
    "            np.savez(f, numerical=np.array(chunk_numerical), textual=np.array(chunk_textual, dtype=object), labels=np.array(chunk_labels))\n",
    "\n",
    "    if len(numerical_features_chunks) == 0:\n",
    "        numerical_features = np.array([])\n",
    "        textual_data = []\n",
    "        labels = np.array([])\n",
    "    else:\n",
    "        numerical_features = np.vstack(numerical_features_chunks)\n",
    "        textual_data = [item for sublist in textual_data_chunks for item in sublist]\n",
    "        labels = np.concatenate(labels_chunks)\n",
    "\n",
    "    if len(numerical_features) < min_samples:\n",
    "        logging.info(f\"Only {len(numerical_features)} samples generated. Supplementing with simulated data.\")\n",
    "        X_num_sim, X_text_sim, y_sim = simulate_clinical_data(n_samples=min_samples - len(numerical_features))\n",
    "        numerical_features = np.vstack([numerical_features, X_num_sim]) if len(numerical_features) > 0 else X_num_sim\n",
    "        textual_data.extend(X_text_sim)\n",
    "        labels = np.concatenate([labels, y_sim]) if len(labels) > 0 else y_sim\n",
    "\n",
    "    return numerical_features, textual_data, labels\n",
    "\n",
    "# Step 3: Extract Textual Embeddings Using BERT with Chunked Processing\n",
    "def get_bert_embeddings(texts, chunk_size=50):\n",
    "    try:\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        model.eval()\n",
    "\n",
    "        embeddings = []\n",
    "        with tqdm(total=len(texts), desc=\"Extracting BERT embeddings\", unit=\"texts\") as pbar:\n",
    "            for i in range(0, len(texts), chunk_size):\n",
    "                chunk = texts[i:i + chunk_size]\n",
    "                inputs = tokenizer(chunk, return_tensors='pt', truncation=True, padding=True, max_length=128, return_attention_mask=True)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                chunk_embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "                embeddings.append(chunk_embeddings)\n",
    "                pbar.update(len(chunk))\n",
    "                check_available_ram()\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in BERT embeddings: {e}. Using random embeddings as fallback.\")\n",
    "        return np.random.rand(len(texts), 768)\n",
    "\n",
    "# Step 4: Define DNN for ADE Prediction (B --> G: LLMs) with Improved Architecture\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Step 5: Train DNN with Improved Hyperparameters\n",
    "def train_dnn(X, y, epochs=200):\n",
    "    try:\n",
    "        model = DNN(input_dim=X.shape[1])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "        X_tensor = torch.FloatTensor(X).float()\n",
    "        y_tensor = torch.FloatTensor(y).float().view(-1, 1)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_tensor)\n",
    "            loss = criterion(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return model, outputs.detach().numpy().flatten()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in DNN training: {e}. Returning random predictions.\")\n",
    "        return None, np.random.rand(len(y))\n",
    "\n",
    "# Step 6: Gradient Boosting with XGBoost (B --> H: AI Models) with Improved Hyperparameters\n",
    "def train_gbm(X, y):\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "        model = xgb.XGBClassifier(max_depth=5, learning_rate=0.05, n_estimators=200, random_state=42)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        y_gbm_pred = model.predict_proba(X_scaled)[:, 1]\n",
    "        return y_gbm_pred\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in GBM training: {e}. Returning random predictions.\")\n",
    "        return np.random.rand(len(y))\n",
    "\n",
    "# Step 7: Ensemble Prediction (C: ADE Prediction & Prevention)\n",
    "def ensemble_predict(y_dnn, y_gbm, w=0.6):\n",
    "    return w * y_dnn + (1 - w) * y_gbm\n",
    "\n",
    "# Step 8: Reinforcement Learning for Treatment Adaptation (C --> J)\n",
    "class TrialEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(TrialEnv, self).__init__()\n",
    "        self.protocol = 1.0\n",
    "        self.state = 0.0\n",
    "        self.step_count = 0\n",
    "        self.max_steps = 10\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.step_count += 1\n",
    "        self.protocol += action[0]\n",
    "        reward = -np.random.random() if action[0] > 0 else -1\n",
    "        self.state = np.array([self.protocol], dtype=np.float32)\n",
    "        done = self.step_count >= self.max_steps\n",
    "        truncated = False\n",
    "        return self.state, reward, done, truncated, {}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.step_count = 0\n",
    "        self.state = np.array([0.0], dtype=np.float32)\n",
    "        self.protocol = 1.0\n",
    "        return self.state, {}\n",
    "\n",
    "def train_rl():\n",
    "    try:\n",
    "        env = TrialEnv()\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=0, learning_rate=0.0003)\n",
    "        model.learn(total_timesteps=2000)\n",
    "        return model, env\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in RL training: {e}. Returning dummy model.\")\n",
    "        env = TrialEnv()\n",
    "        class DummyModel:\n",
    "            def __init__(self):\n",
    "                self.env = env\n",
    "        return DummyModel(), env\n",
    "\n",
    "# Step 9: Evaluate Model (Step 6: Metrics)\n",
    "def evaluate_model(y_true, y_pred_prob):\n",
    "    try:\n",
    "        y_pred_binary = (y_pred_prob > 0.5).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred_binary)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        return f1, roc_auc, pr_auc\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in evaluation: {e}. Returning default metrics.\")\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "# Main Workflow\n",
    "def main():\n",
    "    df = fetch_clinical_trials()\n",
    "    analyze_data(df)\n",
    "    X_num, X_text, y = preprocess_clinical_data(df)\n",
    "\n",
    "    if len(X_num) == 0:\n",
    "        logging.error(\"No data available to process. Exiting.\")\n",
    "        return\n",
    "\n",
    "    X_text_emb = get_bert_embeddings(X_text)\n",
    "    X = np.hstack((X_num, X_text_emb))\n",
    "\n",
    "    eligibility_criteria = X_num[:, 0].mean() if X_num.shape[0] > 0 else 0.0\n",
    "    treatment_protocols = X_num[:, 2].sum() if X_num.shape[0] > 0 else 0.0\n",
    "\n",
    "    dnn_model, y_dnn = train_dnn(X, y)\n",
    "    y_gbm = train_gbm(X, y)\n",
    "    y_pred = ensemble_predict(y_dnn, y_gbm)\n",
    "\n",
    "    f1, roc_auc, pr_auc = evaluate_model(y, y_pred)\n",
    "    logging.info(f\"Evaluation Metrics:\\nF1 Score: {f1:.2f}\\nROC-AUC: {roc_auc:.2f}\\nPR-AUC: {pr_auc:.2f}\\n\")\n",
    "\n",
    "    rl_model, env = train_rl()\n",
    "    protocol_value = env.protocol\n",
    "    personalized_medicine = f\"Protocol adjusted to: {protocol_value:.2f}\"\n",
    "    reduced_costs = f\"Trial costs reduced by optimizing with F1: {f1:.2f}\"\n",
    "\n",
    "    logging.info(f\"Eligibility Criteria (Average Age): {eligibility_criteria:.2f}\")\n",
    "    logging.info(f\"Treatment Protocols (Total Dosage): {treatment_protocols:.2f}\")\n",
    "    logging.info(f\"Personalized Medicine: {personalized_medicine}\")\n",
    "    logging.info(f\"Reduced Trial Costs: {reduced_costs}\")\n",
    "\n",
    "    # Delete temporary file\n",
    "    if os.path.exists(TEMP_FILE):\n",
    "        os.remove(TEMP_FILE)\n",
    "        logging.info(f\"Deleted temporary file: {TEMP_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
